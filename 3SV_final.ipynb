{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8201930,"sourceType":"datasetVersion","datasetId":4859016},{"sourceId":8215681,"sourceType":"datasetVersion","datasetId":4869531}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Section 1: Handwriting to Text Model","metadata":{}},{"cell_type":"code","source":"# necessary imports\n\nimport os\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import layers as layers\n\nfrom tqdm import tqdm\nimport csv","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:21.511125Z","iopub.execute_input":"2024-04-24T12:04:21.511600Z","iopub.status.idle":"2024-04-24T12:04:21.521309Z","shell.execute_reply.started":"2024-04-24T12:04:21.511566Z","shell.execute_reply":"2024-04-24T12:04:21.519999Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# paths for datasets\nsentences_txt_path = \"/kaggle/input/iam-sentences/metadata/sentences.txt\"\nsentences_folder_path = \"/kaggle/input/iam-sentences/dataset\"\n\n# load and process dataset\ndataset, vocab, max_len = [], set(), 0\nwords = open(sentences_txt_path, \"r\").readlines()\nfor line in tqdm(words):\n    if line.startswith(\"#\"):\n        continue\n\n    line_split = line.split(\" \")\n    if line_split[2] == \"err\":\n        continue\n\n    folder1 = line_split[0][:3]\n    folder2 = \"-\".join(line_split[0].split(\"-\")[:2])\n    file_name = line_split[0] + \".png\"\n    label = line_split[-1].rstrip(\"\\n\")\n\n    # replace \"|\" with \" \" in label\n    label = label.replace(\"|\", \" \")\n\n    rel_path = os.path.join(sentences_folder_path, file_name)\n    if not os.path.exists(rel_path):\n        print(f\"File not found: {rel_path}\")\n        continue\n\n    dataset.append([rel_path, label])\n    max_len = max(max_len, len(label))\n\nmax_text_length = max_len\n\n\ncsv_file_path = \"data.csv\"\n\n# write the data to CSV file with labeled columns\nwith open(csv_file_path, mode='w', newline='') as file:\n    writer = csv.writer(file)\n    \n    writer.writerow([\"path\", \"label\"])\n    writer.writerows(dataset)\n\nprint(\"%s has been created successfully.\", csv_file_path);\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:21.523964Z","iopub.execute_input":"2024-04-24T12:04:21.524460Z","iopub.status.idle":"2024-04-24T12:04:29.947061Z","shell.execute_reply.started":"2024-04-24T12:04:21.524416Z","shell.execute_reply":"2024-04-24T12:04:29.939533Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":" 34%|███▎      | 5650/16777 [00:08<00:16, 685.18it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m rel_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(sentences_folder_path, file_name)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# creating pandas dataframe of dataset\ndata = pd.read_csv(\"/kaggle/working/data.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.948714Z","iopub.status.idle":"2024-04-24T12:04:29.949707Z","shell.execute_reply.started":"2024-04-24T12:04:29.949348Z","shell.execute_reply":"2024-04-24T12:04:29.949377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# few example images of dataset\n\nplt.figure(figsize=(15, 10))\n\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = data.loc[i, 'path']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(data.loc[i, 'label'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.951257Z","iopub.status.idle":"2024-04-24T12:04:29.951972Z","shell.execute_reply.started":"2024-04-24T12:04:29.951742Z","shell.execute_reply":"2024-04-24T12:04:29.951765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset cleaning\n\nprint(\"Number of NaNs in train set      : \", data['label'].isnull().sum())\ndata.dropna(axis=0, inplace=True)\n\ndata['label'] = data['label'].str.upper()\ndata.reset_index(inplace = True, drop=True) ","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.953226Z","iopub.status.idle":"2024-04-24T12:04:29.953939Z","shell.execute_reply.started":"2024-04-24T12:04:29.953717Z","shell.execute_reply":"2024-04-24T12:04:29.953742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label statistics\n\ntrain_y_labels_max=0\ntrain_y_labels_sum=0\ntrain_y_labels_count_freq={}\nfor i in range(len(data)):\n    freq=len(data.loc[i,'label'])\n    if freq in train_y_labels_count_freq:\n        train_y_labels_count_freq[freq]=train_y_labels_count_freq[freq]+1\n    else:\n        train_y_labels_count_freq[freq]=1\n    if freq>train_y_labels_max:\n        train_y_labels_max=freq\n    train_y_labels_sum = train_y_labels_sum+freq\n\nprint('max len:', train_y_labels_max)\nprint('avg len:', train_y_labels_sum/len(data))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.955301Z","iopub.status.idle":"2024-04-24T12:04:29.955969Z","shell.execute_reply.started":"2024-04-24T12:04:29.955744Z","shell.execute_reply":"2024-04-24T12:04:29.955772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(list(train_y_labels_count_freq.keys()),list(train_y_labels_count_freq.values()))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.957226Z","iopub.status.idle":"2024-04-24T12:04:29.957884Z","shell.execute_reply.started":"2024-04-24T12:04:29.957643Z","shell.execute_reply":"2024-04-24T12:04:29.957670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# augmenting images to improve model + prevent overfitting\n\n# image augmentation function 1 (unused)\n'''def augment_image1(image):\n    # random gaussian blur\n    if np.random.rand() < 0.5:\n        image = cv2.flip(image, 0)  # horizontal flip\n    if np.random.rand() < 0.5:\n        image = cv2.flip(image, 1)  # vertical flip\n        \n    if np.random.rand() < 0.7:\n        kernel_size = tuple(np.random.randint(3, 6, 2) * 2 + 1)  \n        #kernel_size = tuple(np.random.randint(3, 12, 2) * 2 + 1)  \n        image = cv2.GaussianBlur(image, kernel_size, 0)\n\n    # random brightness adjustment\n    if np.random.rand() < 0.7:\n        brightness_factor = np.random.uniform(0.8, 1.1)\n        image = np.clip(image * brightness_factor, 0, 255).astype(np.uint8)\n\n    # random contrast adjustment\n    if np.random.rand() < 0.7:\n        contrast_factor = np.random.uniform(0.3, 1.3)\n        image = np.clip((image - 127.5) * contrast_factor + 127.5, 0, 255).astype(np.uint8)\n\n    # random saturation adjustment\n    if np.random.rand() < 0.7:\n        saturation_factor = np.random.uniform(0.3, 1.3)\n        hsv_image = cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2HSV)\n        hsv_image[..., 1] = np.clip(hsv_image[..., 1] * saturation_factor, 0, 255)\n        # extracting the value (brightness) channel from the HSV image\n        image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)[:, :, 2]\n        \n    rows, cols = image.shape\n    shear_angle_x = np.random.uniform(-0.8, 0.8)  # range for x-axis shear (-0.2 to 0.2 rads)\n    shear_matrix_x = np.float32([[1, shear_angle_x, 0], [0, 1, 0]])\n    sheared_image = cv2.warpAffine(image.copy(), shear_matrix_x, (cols, rows))\n\n    return sheared_image'''\n\n\n# image augmentation function 2 (used)\ndef augment_image2(image):\n        \n    if np.random.rand() < 0.7:\n        kernel_size = tuple(np.random.randint(3, 6, 2) * 2 + 1)  \n        #kernel_size = tuple(np.random.randint(3, 12, 2) * 2 + 1)  \n        image = cv2.GaussianBlur(image, kernel_size, 0)\n\n    # random brightness adjustment\n    if np.random.rand() < 0.7:\n        brightness_factor = np.random.uniform(0.8, 1.1)\n        image = np.clip(image * brightness_factor, 0, 255).astype(np.uint8)\n\n    # random contrast adjustment\n    if np.random.rand() < 0.7:\n        contrast_factor = np.random.uniform(0.3, 1.3)\n        image = np.clip((image - 127.5) * contrast_factor + 127.5, 0, 255).astype(np.uint8)\n\n    # random saturation adjustment\n    if np.random.rand() < 0.7:\n        saturation_factor = np.random.uniform(0.3, 1.3)\n        hsv_image = cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2HSV)\n        hsv_image[..., 1] = np.clip(hsv_image[..., 1] * saturation_factor, 0, 255)\n        # extracting the value (brightness) channel from HSV image\n        image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)[:, :, 2]\n        \n    rows, cols = image.shape\n    shear_angle_x = np.random.uniform(-0.8, 0.8)  # range for x-axis shear (-0.2 to 0.2 rads)\n    shear_matrix_x = np.float32([[1, shear_angle_x, 0], [0, 1, 0]])\n    sheared_image = cv2.warpAffine(image.copy(), shear_matrix_x, (cols, rows))\n\n    return sheared_image\n\ndef resize_or_pad_image(image, target_height=64, target_width=512):\n    image = cv2.resize(image, (target_width, target_height))\n    return image\n\n\n# resizing + rotating\ndef preprocess(img):\n    (h, w) = img.shape    \n    final_image = resize_or_pad_image(img)\n    return cv2.rotate(final_image, cv2.ROTATE_90_CLOCKWISE)\n\n\n# resizing + augmenting\ndef preprocess1(img):\n    (h, w) = img.shape    \n    final_image = resize_or_pad_image(img)\n    return augment_image2(final_image)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.959909Z","iopub.status.idle":"2024-04-24T12:04:29.960587Z","shell.execute_reply.started":"2024-04-24T12:04:29.960295Z","shell.execute_reply":"2024-04-24T12:04:29.960320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validating resize_or_pad_image function\n\nfor i in range(5):\n    image = cv2.imread(data.loc[i,'path'])\n    image = resize_or_pad_image(image)\n    image_shape = image.shape\n\n    print(\"Shape of the image:\", image_shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.965611Z","iopub.status.idle":"2024-04-24T12:04:29.966171Z","shell.execute_reply.started":"2024-04-24T12:04:29.965906Z","shell.execute_reply":"2024-04-24T12:04:29.965944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validating augmentation function\n\n# example list of paths\nimg_paths = ['/kaggle/input/iam-sentences/dataset/a01-000u-s00-00.png',\n             '/kaggle/input/iam-sentences/dataset/a01-000u-s00-01.png',\n             '/kaggle/input/iam-sentences/dataset/a01-000u-s00-02.png']\n\nplt.figure(figsize=(20, 10))\n\nfor i in range(3):\n    img_path = img_paths[i]\n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    aug_img = preprocess1(img)\n    # print(1)\n    plt.subplot(3, 2, i * 2 + 1)\n    plt.imshow(img, cmap='gray')\n    plt.title(f'Original Image {i + 1}')\n    plt.axis('off')\n\n    plt.subplot(3, 2, i * 2 + 2)\n    plt.imshow(aug_img, cmap='gray')\n    plt.title(f'Augmented Image {i + 1}')\n    plt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.967925Z","iopub.status.idle":"2024-04-24T12:04:29.968398Z","shell.execute_reply.started":"2024-04-24T12:04:29.968183Z","shell.execute_reply":"2024-04-24T12:04:29.968201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.970029Z","iopub.status.idle":"2024-04-24T12:04:29.970465Z","shell.execute_reply.started":"2024-04-24T12:04:29.970261Z","shell.execute_reply":"2024-04-24T12:04:29.970278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# choosing dataset split size\n\ntrain_size = 12080\nvalid_size = 1000\ntest_size = 1000\n\nimg_aug_count = 0","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.973556Z","iopub.status.idle":"2024-04-24T12:04:29.974360Z","shell.execute_reply.started":"2024-04-24T12:04:29.974143Z","shell.execute_reply":"2024-04-24T12:04:29.974163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training data\n\ntrain_x = []\n\nfor i in range(train_size):\n    img_dir = data.loc[i, 'path']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    \n    t=image\n    if random.randint(0, 10) in [1,2,3,4,5]:\n        t= augment_image2(t)\n        img_aug_count=img_aug_count+1\n\n    t = preprocess(t)\n    t = t/255.\n    train_x.append(t)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.976021Z","iopub.status.idle":"2024-04-24T12:04:29.976525Z","shell.execute_reply.started":"2024-04-24T12:04:29.976293Z","shell.execute_reply":"2024-04-24T12:04:29.976311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation data\n\nvalid_x = []\n\nfor i in range(train_size,train_size+valid_size):\n    img_dir = data.loc[i, 'path']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = preprocess(image)\n    image = image/255.\n    valid_x.append(image)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.978349Z","iopub.status.idle":"2024-04-24T12:04:29.979637Z","shell.execute_reply.started":"2024-04-24T12:04:29.979296Z","shell.execute_reply":"2024-04-24T12:04:29.979328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing data\n\ntest_x = []\n\nfor i in range(train_size+valid_size,train_size+test_size+valid_size):\n    img_dir = data.loc[i, 'path']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = preprocess(image)\n    image = image/255.\n    test_x.append(image)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.981959Z","iopub.status.idle":"2024-04-24T12:04:29.982387Z","shell.execute_reply.started":"2024-04-24T12:04:29.982184Z","shell.execute_reply":"2024-04-24T12:04:29.982202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train:',len(train_x),'valid:',len(valid_x),'test:',len(test_x))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.984646Z","iopub.status.idle":"2024-04-24T12:04:29.985541Z","shell.execute_reply.started":"2024-04-24T12:04:29.985211Z","shell.execute_reply":"2024-04-24T12:04:29.985230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.asarray(train_x).shape","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.986777Z","iopub.status.idle":"2024-04-24T12:04:29.987650Z","shell.execute_reply.started":"2024-04-24T12:04:29.987399Z","shell.execute_reply":"2024-04-24T12:04:29.987418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshaping data\n\ntrain_x = np.array(train_x).reshape(-1, 512, 64, 1)\nvalid_x = np.array(valid_x).reshape(-1, 512, 64, 1)\ntest_x = np.array(test_x).reshape(-1, 512, 64, 1)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.989106Z","iopub.status.idle":"2024-04-24T12:04:29.990022Z","shell.execute_reply.started":"2024-04-24T12:04:29.989776Z","shell.execute_reply":"2024-04-24T12:04:29.989794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-,!?.' \" # alphabets our model can identify\nmax_str_len = 95 # max length of input labels\nnum_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\nnum_of_timestamps = 128 # max length of predicted labels\n\n\n# encode + decode functions\ndef label_to_num(label):\n    label_num = []\n    for ch in label:\n        ind=alphabets.find(ch)\n        if ind != -1:\n            label_num.append(ind)\n        else:\n            label_num.append(0)\n    return np.array(label_num)\n\ndef num_to_label(num):\n    ret = \"\"\n    for ch in num:\n        if ch == -1:  # CTC Blank\n            break\n        else:\n            ret+=alphabets[ch]\n    return ret","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.991519Z","iopub.status.idle":"2024-04-24T12:04:29.992305Z","shell.execute_reply.started":"2024-04-24T12:04:29.992069Z","shell.execute_reply":"2024-04-24T12:04:29.992094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validating encoder\nname = 'THREESV'\nprint(name, '\\n',label_to_num(name))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.993964Z","iopub.status.idle":"2024-04-24T12:04:29.994377Z","shell.execute_reply.started":"2024-04-24T12:04:29.994179Z","shell.execute_reply":"2024-04-24T12:04:29.994196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y = np.ones([train_size,max_str_len]) * -1\ntrain_label_len = np.zeros([train_size, 1])\ntrain_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\ntrain_output = np.zeros([train_size])\n\nfor i in range(train_size):\n    train_label_len[i] = len(data.loc[i, 'label'])\n    train_y[i, 0:len(data.loc[i, 'label'])]= label_to_num(data.loc[i, 'label']) ","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.995962Z","iopub.status.idle":"2024-04-24T12:04:29.996412Z","shell.execute_reply.started":"2024-04-24T12:04:29.996211Z","shell.execute_reply":"2024-04-24T12:04:29.996229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_y = np.ones([valid_size, max_str_len]) * -1\nvalid_label_len = np.zeros([valid_size, 1])\nvalid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\nvalid_output = np.zeros([valid_size])\n\nfor i in range(train_size,train_size+valid_size):\n    valid_label_len[i-train_size] = len(data.loc[i, 'label'])\n    valid_y[i-train_size, 0:len(data.loc[i, 'label'])]= label_to_num(data.loc[i, 'label'])  ","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:29.998022Z","iopub.status.idle":"2024-04-24T12:04:29.998752Z","shell.execute_reply.started":"2024-04-24T12:04:29.998544Z","shell.execute_reply":"2024-04-24T12:04:29.998563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y = np.ones([test_size, max_str_len]) * -1\ntest_label_len = np.zeros([test_size, 1])\ntest_input_len = np.ones([test_size, 1]) * (num_of_timestamps-2)\ntest_output = np.zeros([test_size])\n\nfor i in range(train_size+valid_size,train_size+valid_size+test_size):\n    test_label_len[i-(train_size+valid_size)] = len(data.loc[i, 'label'])\n    test_y[i-(train_size+valid_size), 0:len(data.loc[i, 'label'])]= label_to_num(data.loc[i, 'label']) ","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.001542Z","iopub.status.idle":"2024-04-24T12:04:30.002062Z","shell.execute_reply.started":"2024-04-24T12:04:30.001812Z","shell.execute_reply":"2024-04-24T12:04:30.001830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# example of encoding\n\nprint('True label : ',data.loc[10, 'label'] , '\\ntrain_y : ',train_y[10],'\\ntrain_label_len : ',train_label_len[10], '\\ntrain_input_len : ', train_input_len[10])","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.004636Z","iopub.status.idle":"2024-04-24T12:04:30.005360Z","shell.execute_reply.started":"2024-04-24T12:04:30.005131Z","shell.execute_reply":"2024-04-24T12:04:30.005157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MobileNetV2 approach (unused)\n# from tensorflow.keras.applications import MobileNetV2\n\n# Load MobileNetV2 pre-trained on ImageNet, excluding the top layers\n# mobilenet_v2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(512, 64, 3))\n\n# Freeze the pre-trained layers to prevent them from updating during training\n# mobilenet_v2.trainable = False\n\n# from tensorflow.keras.layers import Concatenate,Flatten\n\n\n################ model 1 (MobileNetV2 approach (unused))\n\n# # mobilenetv2\n# from tensorflow.keras.applications import MobileNetV2\n# from tensorflow.keras.layers import Concatenate,Flatten\n\n# input_data = Input(shape=(512, 64, 1), name='input')\n# x = Concatenate()([input_data, input_data, input_data])\n\n# # Load MobileNetV2 without the top (classification) layers\n\n# # Pass input through MobileNetV2\n# mobilenet_output = mobilenet_v2(x)\n\n\n\n# # Additional layers after feature extraction\n# inner = Flatten()(mobilenet_output)\n# inner = Dropout(0.4)(inner)\n\n# # inner = Dense(64, activation='relu', name='dense1')(inner)\n\n# # CNN to RNN\n# inner = Reshape(target_shape=(128, 320), name='reshape')(inner)\n# inner = Dense(128, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n\n# # LSTM layers\n# inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm1')(inner)\n\n# inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm2')(inner)\n\n# # Output layer\n# y_pred = Dense(num_of_characters, activation='softmax', name='output')(inner)\n\n# # # Create model\n# model = Model(inputs=input_data, outputs=y_pred)\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.006941Z","iopub.status.idle":"2024-04-24T12:04:30.007394Z","shell.execute_reply.started":"2024-04-24T12:04:30.007183Z","shell.execute_reply":"2024-04-24T12:04:30.007202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# crnn approach\n\n################# model 2 (crnn approach (used))\ninput_data = Input(shape=(512, 64, 1), name='input')\n\ninner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n\ninner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\ninner = Dropout(0.5)(inner)\n\ninner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\ninner = Conv2D(128, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\n\n\ninner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\ninner = Dropout(0.5)(inner)\n\n# CNN to RNN\ninner = Reshape(target_shape=((128, 1024)), name='reshape')(inner)\ninner = Dense(128, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n\n## RNN\ninner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\ninner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n\n## OUTPUT\ninner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\ny_pred = Activation('softmax', name='softmax')(inner)\n\nmodel = Model(inputs=input_data, outputs=y_pred)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.009713Z","iopub.status.idle":"2024-04-24T12:04:30.010279Z","shell.execute_reply.started":"2024-04-24T12:04:30.010025Z","shell.execute_reply":"2024-04-24T12:04:30.010046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######################### model 3 (squeezenet approach (unused))\n# from tensorflow.keras.layers import Concatenate, Conv2D, MaxPooling2D, Flatten, Reshape, Dense, LSTM, Bidirectional, Input, Activation\n\n# def fire_module(x, fire_id, squeeze=16, expand=64):\n#     \"\"\"\n#     Create a fire module with squeeze and expand layers.\n#     \"\"\"\n#     squeeze_channels = squeeze\n#     expand1_channels = expand\n#     expand3_channels = expand\n\n#     # Squeeze layer\n#     squeeze_layer = Conv2D(squeeze_channels, (1, 1), activation='relu', padding='same', name='fire{}_squeeze'.format(fire_id))(x)\n\n#     # Expand layer 1x1\n#     expand1_layer = Conv2D(expand1_channels, (1, 1), activation='relu', padding='same', name='fire{}_expand1x1'.format(fire_id))(squeeze_layer)\n\n#     # Expand layer 3x3\n#     expand3_layer = Conv2D(expand3_channels, (3, 3), activation='relu', padding='same', name='fire{}_expand3x3'.format(fire_id))(squeeze_layer)\n\n#     # Concatenate the outputs\n#     output = Concatenate(axis=-1, name='fire{}_concatenate'.format(fire_id))([expand1_layer, expand3_layer])\n\n#     return output\n\n# # Define input shape\n# input_data = Input(shape=(512, 64, 1), name='input')\n\n# # SqueezeNet architecture\n# conv1 = Conv2D(64, (3, 3), strides=(2, 2), activation='relu', padding='valid', name='conv1')(input_data)\n# pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(conv1)\n\n# fire2 = fire_module(pool1, fire_id=2, squeeze=16, expand=64)\n# fire3 = fire_module(fire2, fire_id=3, squeeze=16, expand=64)\n# pool3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(fire3)\n# pool3 = Dropout(0.4)(pool3)\n\n# fire4 = fire_module(pool3, fire_id=4, squeeze=32, expand=128)\n# fire5 = fire_module(fire4, fire_id=5, squeeze=32, expand=128)\n# pool5 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(fire5)\n# pool5 = Dropout(0.4)(pool5)\n\n# fire6 = fire_module(pool5, fire_id=6, squeeze=48, expand=192)\n# fire7 = fire_module(fire6, fire_id=7, squeeze=48, expand=192)\n# fire8 = fire_module(fire7, fire_id=8, squeeze=64, expand=256)\n# fire8 = Dropout(0.4)(fire8)\n\n# # Flatten and Dense layers\n# flatten = Flatten(name='flatten')(fire8)\n# # dense1 = Dense(512, activation='relu', name='dense1')(flatten)\n\n# # Reshape for LSTM\n# reshaped_output = Reshape(target_shape=(128, 372))(flatten)\n# inner = Dense(128, activation='relu', kernel_initializer='he_normal', name='dense1')(reshaped_output)\n\n# # LSTM layers\n# lstm1 = Bidirectional(LSTM(256, return_sequences=True), name='lstm1')(inner)\n# lstm2 = Bidirectional(LSTM(256, return_sequences=True), name='lstm2')(lstm1)\n\n# # Output layer\n# y_pred = Dense(num_of_characters, activation='softmax', name='output')(lstm2)\n\n# # Create model\n# model = Model(inputs=input_data, outputs=y_pred)\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.013183Z","iopub.status.idle":"2024-04-24T12:04:30.013833Z","shell.execute_reply.started":"2024-04-24T12:04:30.013568Z","shell.execute_reply":"2024-04-24T12:04:30.013589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###################### model 4 (MobileNetV2 model (unused))\n# # mobilenetv2\n# from tensorflow.keras.applications import MobileNetV2\n# from tensorflow.keras.layers import Concatenate,Flatten\n\n# input_data = Input(shape=(512, 64, 1), name='input')\n# x = Concatenate()([input_data, input_data, input_data])\n\n# # Load MobileNetV2 without the top (classification) layers\n# mobilenet_v2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(512, 64, 3))\n\n# # Pass input through MobileNetV2\n# mobilenet_output = mobilenet_v2(x)\n\n# # Additional layers after feature extraction\n# inner = Flatten()(mobilenet_output)\n# inner = Dropout(0.4)(inner)\n\n# # inner = Dense(64, activation='relu', name='dense1')(inner)\n\n# # CNN to RNN\n# inner = Reshape(target_shape=(128, 320), name='reshape')(inner)\n# inner = Dense(128, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n\n# # LSTM layers\n# inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm1')(inner)\n\n# inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm2')(inner)\n\n# # Output layer\n# y_pred = Dense(num_of_characters, activation='softmax', name='output')(inner)\n\n# # Create model\n# model = Model(inputs=input_data, outputs=y_pred)\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.016413Z","iopub.status.idle":"2024-04-24T12:04:30.016950Z","shell.execute_reply.started":"2024-04-24T12:04:30.016721Z","shell.execute_reply":"2024-04-24T12:04:30.016741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ctc_lambda_func(args):\n    y_pred, labels, input_length, label_length = args\n    # the 2 is critical here since the first couple outputs of the RNN\n    # tend to be garbage\n    y_pred = y_pred[:, 2:, :]\n    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.018982Z","iopub.status.idle":"2024-04-24T12:04:30.019946Z","shell.execute_reply.started":"2024-04-24T12:04:30.019716Z","shell.execute_reply":"2024-04-24T12:04:30.019736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\ninput_length = Input(name='input_length', shape=[1], dtype='int64')\nlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\nctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\nmodel_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)\nmodel_final.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.021679Z","iopub.status.idle":"2024-04-24T12:04:30.022102Z","shell.execute_reply.started":"2024-04-24T12:04:30.021897Z","shell.execute_reply":"2024-04-24T12:04:30.021913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we are using a dummy lambda function, since loss calculation happens elsewhere\noptimizer = Adam(learning_rate=0.001)\nmodel_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n\nhistory=model_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output, \n                validation_data=([valid_x, valid_y, valid_input_len,  valid_label_len], valid_output),\n                epochs=60, batch_size=64,verbose=1)\n# ,callbacks=[early_stopping]","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.023737Z","iopub.status.idle":"2024-04-24T12:04:30.024173Z","shell.execute_reply.started":"2024-04-24T12:04:30.023970Z","shell.execute_reply":"2024-04-24T12:04:30.023988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction examples\nplt.figure(figsize=(40, 25))\nfor i in range(0,5):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = data.loc[i+train_size+valid_size, 'path']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap='gray')\n    \n    image = preprocess(image)\n    image = image/255.\n    pred = model.predict(image.reshape(1, 512, 64, 1))\n    decoded = tf.keras.backend.get_value(tf.keras.backend.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], greedy=True)[0][0])\n    plt.title(num_to_label(decoded[0]), fontsize=12)\n    plt.axis('off')\n    \nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.026075Z","iopub.status.idle":"2024-04-24T12:04:30.027023Z","shell.execute_reply.started":"2024-04-24T12:04:30.026798Z","shell.execute_reply":"2024-04-24T12:04:30.026817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model loss graph\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.028716Z","iopub.status.idle":"2024-04-24T12:04:30.029129Z","shell.execute_reply.started":"2024-04-24T12:04:30.028919Z","shell.execute_reply":"2024-04-24T12:04:30.028948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('threesv.weights.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.034653Z","iopub.status.idle":"2024-04-24T12:04:30.035309Z","shell.execute_reply.started":"2024-04-24T12:04:30.035006Z","shell.execute_reply":"2024-04-24T12:04:30.035032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction array preparation\npreds = model.predict(test_x)\ndecoded = tf.keras.backend.get_value(tf.keras.backend.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], greedy=True)[0][0])\n\nprediction = []\nfor i in range(test_size):\n    prediction.append(num_to_label(decoded[i]))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.037047Z","iopub.status.idle":"2024-04-24T12:04:30.037673Z","shell.execute_reply.started":"2024-04-24T12:04:30.037342Z","shell.execute_reply":"2024-04-24T12:04:30.037366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# attempt to implement word beam search (unused)\ntemp = '''# Define the Word Beam Search decoding function\ndef word_beam_search(prediction, beam_width=25, lm=None): \n    # Replace alphabet with your alphabet if it's different\n    # alphabet = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n    # alphabet = alphabets\n    alphabet = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 \"\n\n    blank_idx = len(alphabet)\n    space_idx = len(alphabet) - 1\n\n    \n    if lm is not None:\n        # Load language model if available\n        lm = open(lm_path).read().split()\n        lm = {lm[i]: float(lm[i + 1]) for i in range(0, len(lm), 2)}\n    \n    print(prediction.shape)\n    V, T = prediction.shape  # T: input len, V: number of labels (including blank)\n    \n    # Step 1: Initialize variables\n    paths = {'': 0}\n    \n    # Step 2: Decode each time step\n    for t in range(T):\n        new_paths = {}\n        \n        # Beam search\n        for path in paths:\n            # Insert blank\n            if path in new_paths:\n                new_paths[path] += prediction[t, blank_idx] * paths[path]\n            else:\n                new_paths[path] = prediction[t, blank_idx] * paths[path]\n            \n            # Insert character\n            idx = np.argmax(prediction[t, :])\n            char = alphabet[idx]\n            if char != '':\n                if path in new_paths:\n                    new_paths[path + char] += prediction[t, idx] * paths[path]\n                else:\n                    new_paths[path + char] = prediction[t, idx] * paths[path]\n                \n            # Insert space\n            if char != '' and char != ' ':\n                if len(path) > 0 and path[-1] != ' ':\n                    if path + ' ' in new_paths:\n                        new_paths[path + ' '] += prediction[t, space_idx] * paths[path]\n                    else:\n                        new_paths[path + ' '] = prediction[t, space_idx] * paths[path]\n        \n        # Prune paths\n        ordered_paths = sorted(new_paths.items(), key=lambda x: x[1], reverse=True)[:beam_width]\n        paths = {k: v for k, v in ordered_paths}\n    \n    # Apply language model if available\n    if lm is not None:\n        for path in paths:\n            words = path.strip().split()\n            score = sum([np.log(lm[w] if w in lm else 0.01) for w in words])\n            paths[path] *= np.exp(score)\n    \n    # Select the most likely path\n    best_path = max(paths, key=paths.get)\n    return best_path.strip()\n\n# Implementing Word Beam Search decoding for the predictions\ndef decode_with_wbs(predictions):\n    decoded_texts = []\n    for pred in predictions:\n        decoded = word_beam_search(pred)\n        decoded_texts.append(decoded)\n    return decoded_texts\n\n\npreds = model.predict(test_x)\n\n# print(preds.shape)\nprediction = []\n\ndecoded_predictions = decode_with_wbs(preds)\nfor text in decoded_predictions:\n    prediction.append(text)'''\n'''","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.040515Z","iopub.status.idle":"2024-04-24T12:04:30.041092Z","shell.execute_reply.started":"2024-04-24T12:04:30.040811Z","shell.execute_reply":"2024-04-24T12:04:30.040835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating word, character accuracy\ny_true = data.loc[train_size+valid_size:train_size+valid_size+test_size, 'label']\n\n\ndef calculate_accuracy(y_true, y_pred):\n    total_words = 0\n    correct_words = 0\n    total_char = 0\n    correct_char = 0\n\n    for true_sentence, pred_sentence in zip(y_true, y_pred):\n        true_words = true_sentence.split()\n        pred_words = pred_sentence.split()\n        \n\n        total_words += len(true_words)\n\n        # word accuracy\n        for true_word, pred_word in zip(true_words, pred_words):\n            if true_word == pred_word:\n                correct_words += 1\n\n            total_char += len(true_word)\n            \n            # character accuracy\n            for j in range(min(len(true_word), len(pred_word))):\n                if true_word[j] == pred_word[j]:\n                    correct_char += 1\n\n    word_accuracy = correct_words / total_words if total_words > 0 else 0\n    character_accuracy = correct_char/ total_char if total_char> 0 else 0\n\n    return word_accuracy, character_accuracy\n\n\nword_accuracy, character_accuracy = calculate_accuracy(y_true, prediction)\nprint(\"Word Accuracy:\", word_accuracy)\nprint(\"Character Accuracy:\", character_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.042668Z","iopub.status.idle":"2024-04-24T12:04:30.043217Z","shell.execute_reply.started":"2024-04-24T12:04:30.042941Z","shell.execute_reply":"2024-04-24T12:04:30.042965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Section 2: Answer Script Evaluation","metadata":{}},{"cell_type":"code","source":"# self-curated dataset of handwritten answer scripts\nfolderpath='/kaggle/input/handwritten-answers-zip/Handwritten_Answers'\n\n# function to extract data from filenames\n    # if the roll number starts with Correct, it is a correct answer\n    # if it starts with Incorrect, it is a wrong answer\n    #### we have added the correctness of data into the roll number to make it easier to understand and calculate accuracy\ndef extract_data(filename):\n    parts = filename.split(\"_\")\n    if len(parts) != 4:\n        raise ValueError(\"Invalid filename format\")\n    question_number = parts[1]\n    correctness = parts[3]\n    \n    if correctness == 'C':\n        roll_number = 'Correct_'+parts[2]\n    else:\n        roll_number = 'Incorrect_'+parts[2]\n        \n    return question_number, roll_number, correctness\n\n# function to write data into a csv\ndef write_to_csv(filenames, csv_filename):\n    with open(csv_filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow([\"Question Number\", \"Roll Number\", \"Correctness\", \"Filepath\"])\n        for filename in filenames:\n            try:\n                question_number, roll_number, correctness = extract_data(filename)\n                filepath = folderpath + '/' + filename\n                writer.writerow([question_number, roll_number, correctness, filepath])\n            except ValueError as e:\n                print(f\"Error processing file {filename}: {e}\")\n\n# function to get list of filenames\ndef get_filelist(folder_path):\n    filelist = []\n    for filename in os.listdir(folder_path):\n        filelist.append(filename)\n    return filelist","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.045604Z","iopub.status.idle":"2024-04-24T12:04:30.046194Z","shell.execute_reply.started":"2024-04-24T12:04:30.045883Z","shell.execute_reply":"2024-04-24T12:04:30.045906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creates csv and data frame of data\nfilenames = get_filelist(folderpath)\ncsv_filename = \"answer_scripts.csv\"\nwrite_to_csv(filenames, csv_filename)\ndf = pd.read_csv(\"answer_scripts.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.047927Z","iopub.status.idle":"2024-04-24T12:04:30.048504Z","shell.execute_reply.started":"2024-04-24T12:04:30.048198Z","shell.execute_reply":"2024-04-24T12:04:30.048220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing answer scripts\nprocessed_images = []\np_dataset = df[\"Filepath\"].tolist()\n\nfor i in p_dataset:\n    image = cv2.imread(i, cv2.IMREAD_GRAYSCALE)\n    image = preprocess(image)\n    image = image/255.\n    processed_images.append(image)\n\nprocessed_images = np.array(processed_images).reshape(-1, 512, 64, 1)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.050056Z","iopub.status.idle":"2024-04-24T12:04:30.050635Z","shell.execute_reply.started":"2024-04-24T12:04:30.050324Z","shell.execute_reply":"2024-04-24T12:04:30.050346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# digitizing answer scripts by running our model on it\n\nans = model.predict(processed_images)\np_decoded = tf.keras.backend.get_value(tf.keras.backend.ctc_decode(ans, input_length=np.ones(ans.shape[0])*ans.shape[1], greedy=True)[0][0])\n\n# decoding and preparing prediction string array\np_prediction = []\nfor i in range(len(p_decoded)):\n    x = num_to_label(p_decoded[i])\n    print(x)\n    nx=''\n    for e in x:\n        if e == \"'\" or e == \".\":\n            continue\n        else:\n            nx+=e\n    p_prediction.append(nx.strip())","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.052130Z","iopub.status.idle":"2024-04-24T12:04:30.052709Z","shell.execute_reply.started":"2024-04-24T12:04:30.052396Z","shell.execute_reply":"2024-04-24T12:04:30.052417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Student Answer'] = p_prediction","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.054542Z","iopub.status.idle":"2024-04-24T12:04:30.055115Z","shell.execute_reply.started":"2024-04-24T12:04:30.054808Z","shell.execute_reply":"2024-04-24T12:04:30.054832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display answer script image, expected answer and model prediction\n\nplt.figure(figsize=(15, 10))\n\nfor i in range(10, 20, 2):\n    ax = plt.subplot(3, 2, i+1)\n    img_dir = df.loc[i, 'Filepath']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(expected[df.loc[i, 'Question Number']], fontsize=12)\n    plt.title(df.loc[i, 'Student Answer'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.056692Z","iopub.status.idle":"2024-04-24T12:04:30.057254Z","shell.execute_reply.started":"2024-04-24T12:04:30.056968Z","shell.execute_reply":"2024-04-24T12:04:30.056990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install necessary modules\n%pip install python-Levenshtein","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.059062Z","iopub.status.idle":"2024-04-24T12:04:30.059634Z","shell.execute_reply.started":"2024-04-24T12:04:30.059332Z","shell.execute_reply":"2024-04-24T12:04:30.059357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function that awards students scores based on the Levenshtein distance from expected answers\nimport Levenshtein\n\ndef evaluate_answers(df, expected):\n    df['Score'] = None\n\n    for index, row in df.iterrows():\n        question_number = row['Question Number'] - 1\n        expected_answer = expected[question_number]\n        student_answer = row['Student Answer']\n        df.at[index, 'Score'] = Levenshtein.distance(expected_answer, student_answer)\n\n    return df\n\nexpected = ['SO BEAUTIFUL SO ELEGANT', 'YOU ARE MY SUNSHINE', 'BLOOD IS THICKER THAN WATER', 'HONESTY IS THE BEST POLICY', 'GOOD THINGS TAKE TIME']\n\nevaluated_df = evaluate_answers(df.copy(), expected)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.061436Z","iopub.status.idle":"2024-04-24T12:04:30.061997Z","shell.execute_reply.started":"2024-04-24T12:04:30.061726Z","shell.execute_reply":"2024-04-24T12:04:30.061747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column of our evaluated answer\ndef predict_from_score(score):\n    return 'W' if score > 3 else 'C'\n\ndf['Evaluated Answer'] = df['Score'].apply(predict_from_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.063934Z","iopub.status.idle":"2024-04-24T12:04:30.064501Z","shell.execute_reply.started":"2024-04-24T12:04:30.064210Z","shell.execute_reply":"2024-04-24T12:04:30.064232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking if our predictions are correct or wrong\n\ncorrect_predictions = (df['Evaluated answer'] == df['Correctness']).sum()\ntotal_predictions = len(df)\n\naccuracy = correct_predictions / total_predictions\n\nprint(\"Accuracy of evaluation: \"+ accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:04:30.065905Z","iopub.status.idle":"2024-04-24T12:04:30.066497Z","shell.execute_reply.started":"2024-04-24T12:04:30.066205Z","shell.execute_reply":"2024-04-24T12:04:30.066227Z"},"trusted":true},"execution_count":null,"outputs":[]}]}